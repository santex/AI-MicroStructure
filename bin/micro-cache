#!/usr/bin/perl
use strict;
use warnings;
use Data::Printer;
use Text::Autoformat;
use Getopt::Long;
require AI::Categorizer;
require AI::Categorizer::Learner::NaiveBayes;
require AI::Categorizer::Document;
require AI::Categorizer::KnowledgeSet;
require Lingua::StopWords;
require AI::MicroStructure;
use Parallel::Iterator qw( iterate );
use AnyEvent::Subprocess::Easy qw(qx_nonblock);
use Storable qw(lock_store lock_retrieve);
use Search::ContextGraph;
binmode STDOUT, ":utf8";

 my $cg = Search::ContextGraph->new();

 # first you add some documents, perhaps all at once...

 my %docs = ();


  my $micro = new AI::MicroStructure();
  my $curSysDate = qx_nonblock('date +"%F"')->recv;
     $curSysDate=~ s/\n//g;

our %opts = (       query=>"FEMA camps",
                    max_cache_age => 5,
                    cache_file    => sprintf("%s/search_%s.cache",
                                              $micro->{state}->{cfg}->{"default"},
                                              $curSysDate),
                    cache         => 0,
);
GetOptions (\%opts, "query=s",
                    "max_cache_age=i",
                    "cache_file=s",
                    "cache=i",
                    );

our $cache = {};



eval {
    local $^W = 0;  # because otherwhise doesn't pass errors

    $cache = lock_retrieve($opts{cache_file});

    $cache = {} unless $cache;

    warn "New cache!\n" unless defined $cache;
};




my $chaps = {};#$cache;
my $qq = "";
my $search = "";

my $test_set =

  {
  };


my $meta = AI::MicroStructure->new;
my $i = 0;

$search = join("|",@ARGV);


my @t=$meta->structures();
push @t,keys %$cache;
my $q = rand($#t);

my @look = grep{/$search/}@t;

@t =  grep{!/$search/}@t;
foreach(@look){
    my @all = split(/\n/,`micrownet $_`);
    my $name = $_;
    if($#all>3){
    $test_set->{$name}={subject=>sprintf("%s %s ",shift @all ,shift @all),body=> join(" ",@all) };
    }
}


#map{$a=$_; $a=`micro $a all`; $a=~s/\n/|/g; $_=substr($a,0,length($a)-1);}
#die($search);
sub fromWordlist
{
  my $string = shift;
  return () unless  $string;
  my $call = "cat /home/santex/data-hub/stream/freq-raw.m* | egrep -i '$string'";
#die($call);
  my $out = qx_nonblock($call)->recv;

  my @out = split("\n",$out);

  return @out;
}


sub trim
{
  my $string = shift;
  $string =  "" unless  $string;
  $string =~ s/^\s+//;
  $string =~ s/\s+$//;
  $string =~ s/\t//;
  $string =~ s/^\s//;
  return $string;
}


my %features = (content_weights => {subject => 2,
                                    body => 1},
                stopwords => Lingua::StopWords::getStopWords('en'),
                stemming => 'porter',
               );

# this is the raw data to train with, which associates
# numerical categories with subjects and bodies
#push @t,fromWordlist($search)  unless($opts{cache});
my $ch ={};

foreach(@t){

$ch->{$_}=1;

}

foreach(keys %$ch){

    next if $_=~ m/'/;
    next unless $_;
    printf("\n%d\t%s",$i, $_);
    if($cache->{$_}){
  $qq=$cache->{$_};
}else{
    $qq=`micrownet $_`;#")->recv;
  $cache->{$_}=[split("\n",$qq)];
    }
    next unless $qq;

    $chaps->{$i}={subject=>$_,body=> join(" ",$cache->{$_})};

#   $cg->add( $_,[$cache->{$_}]);



    $i++;
}

lock_store($cache, $opts{cache_file});
printf("\n");

# create documents from $chaps to train with
my $docs;
foreach my $cat(keys %$chaps) {
next if $cat=~/'/;

  $docs->{$cat} = {categories => [$cat],
       content => {subject => $chaps->{$cat}->{subject},
             body => $chaps->{$cat}->{body},
            },
      };
}
my $c =
  AI::Categorizer->new(
           knowledge_set =>
           AI::Categorizer::KnowledgeSet->new( name => 'CSL'),
           verbose => 1,
          );
while (my ($name, $data) = each %$docs) {

  $c->knowledge_set->make_document(name => $name, %$data, %features);
  $cg->add( $name,[values %$data]) unless(!$name);

}
my $learner = $c->learner;
$learner->train;

# this is a test data set to categorize,
# based on the training done above




# see what category each element of $test_set gets put into,
# using a threshold score of 0.9
my $threshold = 0.9;
while (my ($name, $data) = each   %$test_set) {
  my $doc = AI::Categorizer::Document->new(name =>$name,
             content =>  $data,
             %features);

  my $r = $learner->categorize($doc);
  $r->threshold($threshold);
  my $b = $r->best_category;
print autoformat sprintf("%s is in category %d, %s with score %.3f\n",
   $name, $b,$chaps->{$b}->{subject}, $r->scores($b));
}


  my ( $sdocs, $swords ) = $cg->search('bio');

print Dumper $cg->search('bio');

p $sdocs;
p $swords;
p $test_set;
